{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - I: Using dropouts after conv and FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,MaxPool2D,Conv2D,Activation,BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2 \n",
    "from tensorflow.keras import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch, classes, epochs\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((50000, 32, 32, 3), (50000, 1)), ((10000, 32, 32, 3), (10000, 1)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape,y_train.shape),(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making data shape suitable for input. X_train,y_train are already in required shape. weneed to convert y_train & y_test to (50000,10) and (10000,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train,10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(3,3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd conv layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(3,3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 356,874\n",
      "Trainable params: 356,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# convert to float, normalise the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 102s 2ms/sample - loss: 2.0365 - accuracy: 0.2400 - val_loss: 1.8105 - val_accuracy: 0.3350\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 102s 2ms/sample - loss: 1.7906 - accuracy: 0.3383 - val_loss: 1.6579 - val_accuracy: 0.3977\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 95s 2ms/sample - loss: 1.6586 - accuracy: 0.3863 - val_loss: 1.4990 - val_accuracy: 0.4604\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.5556 - accuracy: 0.4314 - val_loss: 1.4585 - val_accuracy: 0.4754\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 83s 2ms/sample - loss: 1.4778 - accuracy: 0.4593 - val_loss: 1.3842 - val_accuracy: 0.4960\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.4232 - accuracy: 0.4865 - val_loss: 1.2883 - val_accuracy: 0.5322\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 1.3784 - accuracy: 0.4992 - val_loss: 1.2589 - val_accuracy: 0.5464\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 1.3330 - accuracy: 0.5180 - val_loss: 1.2102 - val_accuracy: 0.5722\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 81s 2ms/sample - loss: 1.2989 - accuracy: 0.5327 - val_loss: 1.3053 - val_accuracy: 0.5386\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 80s 2ms/sample - loss: 1.2634 - accuracy: 0.5464 - val_loss: 1.2045 - val_accuracy: 0.5731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18022814048>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(x_train,y_train,batch_size  = batch_size,epochs=10,validation_data=(x_test,y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - II: Remove the dropouts after the convolutional layers (but retain them in the FC layer). Also, use batch normalization after every convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#2nd conv layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 357,514\n",
      "Trainable params: 357,194\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 1.7156 - accuracy: 0.3818 - val_loss: 18.1045 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 1.3698 - accuracy: 0.5101 - val_loss: 5.6404 - val_accuracy: 0.2206\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 91s 2ms/sample - loss: 1.2214 - accuracy: 0.5678 - val_loss: 10.1879 - val_accuracy: 0.1495\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 1.1238 - accuracy: 0.6035 - val_loss: 13.1101 - val_accuracy: 0.1133\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 91s 2ms/sample - loss: 1.0369 - accuracy: 0.6346 - val_loss: 4.2972 - val_accuracy: 0.1946\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 88s 2ms/sample - loss: 0.9775 - accuracy: 0.6571 - val_loss: 6.3295 - val_accuracy: 0.2002\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 85s 2ms/sample - loss: 0.9268 - accuracy: 0.6745 - val_loss: 13.3669 - val_accuracy: 0.1049\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 91s 2ms/sample - loss: 0.8815 - accuracy: 0.6920 - val_loss: 4.9256 - val_accuracy: 0.2382\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 0.8460 - accuracy: 0.7046 - val_loss: 7.4388 - val_accuracy: 0.1645\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 87s 2ms/sample - loss: 0.8087 - accuracy: 0.7149 - val_loss: 9.8025 - val_accuracy: 0.1464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1803129eb88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# convert to float, normalise the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# train\n",
    "model.fit(x_train,y_train,batch_size  = batch_size,epochs=10,validation_data=(x_test,y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we can observed overfitting. this is becuase we have removed dropouts.we removed the dropouts to make model less complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - III: Use batch normalization and dropouts after every convolutional layer. Also, retain the dropouts in the FC layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd conv layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 357,514\n",
      "Trainable params: 357,194\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 98s 2ms/sample - loss: 1.8420 - accuracy: 0.3449 - val_loss: 1.4597 - val_accuracy: 0.4638\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 97s 2ms/sample - loss: 1.4946 - accuracy: 0.4552 - val_loss: 1.2738 - val_accuracy: 0.5382\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 1.3828 - accuracy: 0.5013 - val_loss: 1.2556 - val_accuracy: 0.5567\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 94s 2ms/sample - loss: 1.2989 - accuracy: 0.5321 - val_loss: 1.2769 - val_accuracy: 0.5468\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 91s 2ms/sample - loss: 1.2358 - accuracy: 0.5572 - val_loss: 1.0656 - val_accuracy: 0.6240\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 93s 2ms/sample - loss: 1.1817 - accuracy: 0.5758 - val_loss: 1.3512 - val_accuracy: 0.5282\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 1.1319 - accuracy: 0.5940 - val_loss: 1.1610 - val_accuracy: 0.5891\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 1.0991 - accuracy: 0.6103 - val_loss: 0.9399 - val_accuracy: 0.6665\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 94s 2ms/sample - loss: 1.0757 - accuracy: 0.6159 - val_loss: 1.3440 - val_accuracy: 0.5583\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 130s 3ms/sample - loss: 1.0499 - accuracy: 0.6274 - val_loss: 1.1456 - val_accuracy: 0.5922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e44b9c0108>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# convert to float, normalise the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# train\n",
    "model.fit(x_train,y_train,batch_size  = batch_size,epochs=10,validation_data=(x_test,y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we got significant improvement. though training acc goes down becuase we have included dropouts.but there is no overfitting.Dropouts is basically a regularization technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - IV: Remove the dropouts after the convolutional layers and use L2 regularization in the FC layer. Retain the dropouts in FC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets replace dropouts with L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "#2nd conv layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer = l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 357,514\n",
      "Trainable params: 357,194\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 6.3386 - accuracy: 0.0980 - val_loss: 5.1933 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 4.4525 - accuracy: 0.0985 - val_loss: 3.8495 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 116s 2ms/sample - loss: 3.4531 - accuracy: 0.0978 - val_loss: 3.1304 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 95s 2ms/sample - loss: 2.9183 - accuracy: 0.1004 - val_loss: 2.7456 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 96s 2ms/sample - loss: 2.6321 - accuracy: 0.0986 - val_loss: 2.5396 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 98s 2ms/sample - loss: 2.4790 - accuracy: 0.0974 - val_loss: 2.4294 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 2.3970 - accuracy: 0.0966 - val_loss: 2.3705 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 2.3532 - accuracy: 0.0984 - val_loss: 2.3389 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 2.3297 - accuracy: 0.0966 - val_loss: 2.3220 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 118s 2ms/sample - loss: 2.3172 - accuracy: 0.0965 - val_loss: 2.3130 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e48362a3c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# convert to float, normalise the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# train\n",
    "model.fit(x_train,y_train,batch_size  = batch_size,epochs=10,validation_data=(x_test,y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we can see here overfitting. le regularization not worked well. drop out working good.l2 regul. trying to keep downn weights down.while dropouts trying to throgh out redundant weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment-V: Dropouts after conv layer, L2 in FC, use BN after convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd conv layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(3,3))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer = l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               295424    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 357,514\n",
      "Trainable params: 357,194\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 120s 2ms/sample - loss: 5.8425 - accuracy: 0.3505 - val_loss: 4.3138 - val_accuracy: 0.4849\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 109s 2ms/sample - loss: 3.6293 - accuracy: 0.4673 - val_loss: 2.9180 - val_accuracy: 0.5153\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 2.5236 - accuracy: 0.5159 - val_loss: 2.1173 - val_accuracy: 0.5450\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 1.9155 - accuracy: 0.5504 - val_loss: 1.6738 - val_accuracy: 0.5826\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 1.5673 - accuracy: 0.5799 - val_loss: 1.4215 - val_accuracy: 0.6026\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 119s 2ms/sample - loss: 1.3599 - accuracy: 0.6054 - val_loss: 1.2872 - val_accuracy: 0.6077\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 1.2402 - accuracy: 0.6249 - val_loss: 1.2197 - val_accuracy: 0.6200\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 104s 2ms/sample - loss: 1.1559 - accuracy: 0.6428 - val_loss: 1.0384 - val_accuracy: 0.6833\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 1.0989 - accuracy: 0.6616 - val_loss: 1.0401 - val_accuracy: 0.6711\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 104s 2ms/sample - loss: 1.0622 - accuracy: 0.6726 - val_loss: 1.0545 - val_accuracy: 0.6666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26875334688>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# convert to float, normalise the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# train\n",
    "model.fit(x_train,y_train,batch_size  = batch_size,epochs=10,validation_data=(x_test,y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment-VI: Add a new convolutional layer to the network. Note that by a 'convolutional layer', the professor is referring to a convolutional unit with two sets of Conv2D layers with 128 filters each (we are abusing the terminology a bit here). The code for the additional conv layer is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd conv layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# new conv layer addition\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer = l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 874,890\n",
      "Trainable params: 874,058\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 333s 7ms/sample - loss: 2.5983 - accuracy: 0.0986 - val_loss: 2.5159 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 287s 6ms/sample - loss: 2.4611 - accuracy: 0.0989 - val_loss: 2.4168 - val_accuracy: 0.0841\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 316s 6ms/sample - loss: 2.3876 - accuracy: 0.0957 - val_loss: 2.3639 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 323s 6ms/sample - loss: 2.3482 - accuracy: 0.0980 - val_loss: 2.3354 - val_accuracy: 0.1001\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 329s 7ms/sample - loss: 2.3271 - accuracy: 0.0999 - val_loss: 2.3202 - val_accuracy: 0.0990\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 305s 6ms/sample - loss: 2.3158 - accuracy: 0.0966 - val_loss: 2.3120 - val_accuracy: 0.0773\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 295s 6ms/sample - loss: 2.3097 - accuracy: 0.0994 - val_loss: 2.3077 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 335s 7ms/sample - loss: 2.3065 - accuracy: 0.0955 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 311s 6ms/sample - loss: 2.3047 - accuracy: 0.0990 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 284s 6ms/sample - loss: 2.3038 - accuracy: 0.0962 - val_loss: 2.3034 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2687108e1c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train/255\n",
    "x_xest = x_test/255\n",
    "\n",
    "model.fit(x_train,y_train,batch_size = batch_size,epochs=10,validation_data=(x_test,y_test),shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see here that dropouts play a key role in regularization in neural networks.We have some marginal improvement after adding 1 more conv layer.though it kaes little more time in computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment - VII: Add more feature maps to the conv layers: from 32 to 64 and 64 to 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd conv layer\n",
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer = l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,424,458\n",
      "Trainable params: 4,423,818\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 668s 13ms/sample - loss: 9.5271 - accuracy: 0.0989 - val_loss: 11.1548 - val_accuracy: 0.1155\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 753s 15ms/sample - loss: 6.1498 - accuracy: 0.0999 - val_loss: 6.8772 - val_accuracy: 0.1385\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 763s 15ms/sample - loss: 4.3622 - accuracy: 0.0998 - val_loss: 8.8813 - val_accuracy: 0.1187\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 498s 10ms/sample - loss: 3.4056 - accuracy: 0.0990 - val_loss: 3.3236 - val_accuracy: 0.1222\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 508s 10ms/sample - loss: 2.8932 - accuracy: 0.0985 - val_loss: 2.8014 - val_accuracy: 0.1257\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 489s 10ms/sample - loss: 2.6190 - accuracy: 0.0994 - val_loss: 2.5429 - val_accuracy: 0.1359\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 598s 12ms/sample - loss: 2.4721 - accuracy: 0.0992 - val_loss: 2.4303 - val_accuracy: 0.1352\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 671s 13ms/sample - loss: 2.3935 - accuracy: 0.0986 - val_loss: 2.3659 - val_accuracy: 0.1330\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 644s 13ms/sample - loss: 2.3515 - accuracy: 0.0986 - val_loss: 2.3323 - val_accuracy: 0.1343\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 632s 13ms/sample - loss: 2.3289 - accuracy: 0.0971 - val_loss: 2.3200 - val_accuracy: 0.1076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26873e461c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train/255\n",
    "x_xest = x_test/255\n",
    "\n",
    "model.fit(x_train,y_train,batch_size = batch_size,epochs=10,validation_data=(x_test,y_test),shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these experiments, we saw that the performance of CNNs depends heavily on multiple hyperparameters - the number of layers, number of feature maps in each layer, the use of dropouts, batch normalisation, etc. Thus, it is advisable to first fine-tune your model hyperparameters by conducting lots of experiments. Only when you are convinced that you have found the right set of hyperparameters you should train the model with a larger number of epochs (since almost always the amount of time and computing power you have is limited)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
